# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

### Решение для обеспечения процесса разработки

### Введение
Для обеспечения процесса разработки с учетом указанных требований, предлагаю использовать комбинацию следующих облачных инструментов и технологий:

### Инструменты и технологии

1. **GitHub или GitLab** (для системы контроля версий)
   - Оба инструмента предоставляют мощные возможности для управления исходным кодом с использованием Git. Они поддерживают создание репозиториев для каждого сервиса, а также интеграцию с CI/CD системами.

2. **GitHub Actions или GitLab CI/CD** (для непрерывной интеграции и непрерывной поставки)
   - Эти инструменты позволяют настраивать автоматические сборки и развертывания на основе событий в репозитории (например, push, pull request). Они также поддерживают запуск сборок по кнопке с указанием параметров.

3. **Docker** (для создания собственных образов)
   - Docker позволяет создавать контейнеры для приложений, что упрощает процесс сборки и развертывания. Вы можете создать собственные докер-образы для сборки проектов, что обеспечит консистентность окружения.

4. **HashiCorp Vault или AWS Secrets Manager** (для безопасного хранения секретных данных)
   - Эти инструменты обеспечивают безопасное хранение и управление секретами, такими как пароли и ключи доступа, что критично для безопасности приложений.

5. **Jenkins или CircleCI** (для более сложных сценариев CI/CD)
   - Если требуется более сложная настройка, можно использовать Jenkins или CircleCI, которые позволяют создавать кастомные шаги при сборке и поддерживают параллельный запуск сборок и тестов.

6. **Kubernetes** (для управления контейнерами)
   - Если необходимо развертывание на собственных серверах, Kubernetes может быть использован для управления контейнерами и развертывания агентов сборки.

### Обоснование выбора

- **Облачная система**: Все предложенные инструменты работают в облаке, что обеспечивает доступность и масштабируемость.
- **Система контроля версий Git**: GitHub и GitLab являются стандартами в индустрии, обеспечивая надежное управление версиями.
- **Репозиторий на каждый сервис**: GitHub и GitLab позволяют создавать отдельные репозитории для каждого сервиса, что упрощает управление проектами.
- **Запуск сборки по событию и по кнопке**: GitHub Actions и GitLab CI/CD поддерживают триггеры для автоматического запуска сборок.
- **Настройки и шаблоны для сборок**: Оба инструмента позволяют создавать конфигурации и шаблоны для различных сценариев сборки.
- **Безопасное хранение секретов**: HashiCorp Vault и AWS Secrets Manager обеспечивают надежное хранение секретных данных.
- **Несколько конфигураций для сборки**: CI/CD системы позволяют настраивать различные конфигурации для одной и той же сборки.
- **Кастомные шаги и докер-образы**: Jenkins и CircleCI позволяют добавлять кастомные шаги и использовать докер-образы для сборки.
- **Параллельный запуск**: Все предложенные инструменты поддерживают параллельный запуск сборок и тестов, что значительно ускоряет процесс разработки.

### Заключение
Таким образом, предложенное решение обеспечивает гибкость, безопасность и масштабируемость процесса разработки, соответствуя всем указанным требованиям.


## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

### Решение для сбора и анализа логов в микросервисной архитектуре

Для обеспечения сбора и анализа логов в микросервисной архитектуре можно использовать стек ELK (Elasticsearch, Logstash, Kibana) или его альтернативы, такие как EFK (Elasticsearch, Fluentd, Kibana). Рассмотрим решение на основе стека ELK, так как он широко используется и имеет хорошую поддержку.

### Архитектура решения

1. **Сбор логов**:
   - **Logstash**: Используется для сбора, обработки и отправки логов. Logstash может быть настроен для получения логов из stdout приложений, что соответствует минимальным требованиям к приложениям. Он может работать в режиме "forwarder", получая логи через различные плагины (например, `beats` или `syslog`).
   - **Filebeat**: Легковесный агент, который может быть установлен на каждом хосте. Он будет отслеживать файлы логов или stdout приложений и отправлять их в Logstash или напрямую в Elasticsearch. Filebeat минимизирует нагрузку на приложения и обеспечивает надежную доставку логов.

2. **Центральное хранилище**:
   - **Elasticsearch**: Используется для хранения и индексации логов. Он обеспечивает высокую производительность поиска и фильтрации по записям логов. Elasticsearch поддерживает горизонтальное масштабирование, что позволяет обрабатывать большие объемы данных.

3. **Анализ и визуализация**:
   - **Kibana**: Веб-интерфейс для визуализации и анализа логов, который позволяет разработчикам выполнять поиск по записям логов, создавать дашборды и графики. Kibana предоставляет возможность делиться ссылками на сохраненные поисковые запросы, что соответствует требованиям.

### Принципы взаимодействия компонентов

- **Сбор логов**: Приложения выводят логи в stdout. Filebeat на каждом хосте собирает эти логи и отправляет их в Logstash или напрямую в Elasticsearch.
- **Обработка логов**: Logstash может обрабатывать логи (например, фильтровать, преобразовывать) перед отправкой их в Elasticsearch. Это позволяет стандартизировать формат логов и извлекать полезную информацию.
- **Хранение и индексация**: Elasticsearch принимает обработанные логи и индексирует их, что позволяет быстро выполнять поисковые запросы.
- **Визуализация**: Kibana подключается к Elasticsearch и предоставляет интерфейс для поиска, фильтрации и визуализации данных. Разработчики могут создавать дашборды и делиться ссылками на них.

### Обоснование выбора

- **Гибкость и масштабируемость**: Стек ELK легко масштабируется и может обрабатывать большие объемы данных, что критично для микросервисной архитектуры.
- **Поддержка и сообщество**: ELK имеет большое сообщество и множество ресурсов для обучения и поддержки.
- **Минимальные требования к приложениям**: Использование stdout для логирования позволяет легко интегрировать решение в существующие приложения без значительных изменений.
- **Надежная доставка логов**: Filebeat и Logstash обеспечивают надежную доставку логов, включая механизмы повторной отправки в случае ошибок.

Таким образом, использование стека ELK (или EFK) является эффективным решением для сбора и анализа логов в микросервисной архитектуре, соответствующим всем указанным требованиям.


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
